# -*- coding: utf-8 -*-

import os
import json
import numpy

from collections import Counter

class AbstractBagOfWordsModeler:
    
    def __init__(self):
        pass

    # Simple normalization function
    def simpleNormalizeBag(self, bag):
        normalizedBag = []
        
        if len(bag) > 0:
            labels, values = zip(*bag)
            totalSum = float(sum(values))
            
            for tpl in bag:
                occurrences = tpl[1]
                normalizedOccurrences = occurrences/totalSum
                normalizedTuple = (tpl[0], normalizedOccurrences)
                normalizedBag.append(normalizedTuple)
            
        return normalizedBag
        
    def buildLexicon(self, corpus):
        lexicon = set()
        for doc in corpus:
            bagOfWords = doc['bag_of_words']
            wordsList = list(bagOfWords)
            for word in wordsList:
                lexicon.update([word[0]])
                
        return lexicon
        
    def termFrequency(self, term, document):
      return self.freq(term, document)
    
    def freq(self, term, document):
        for myTuple in document:
            if myTuple[0] == term:
                return myTuple[1]
        return 0
        
    def build_DocTermMatrix(self, docsStructList):
        matrix = []
        vocabulary = self.buildLexicon(docsStructList)
        for struct in docsStructList:
            doc = struct['bag_of_words']
            tf_vector = [self.termFrequency(word, doc) for word in vocabulary]
            matrix.append(tf_vector)
            
        return matrix
    
    # Build tokeinez struct from file
    def buildStruct_FromFile(self, inputFilesFolder, filename):
        
        bag = None
        fileFullNamePath = inputFilesFolder + "/" + filename
        
        jsonData = open(fileFullNamePath)
        tokenizedAssembly = json.load(jsonData)
        bag = self.buildBag_FromArray(tokenizedAssembly)
        normalizedModel = self.simpleNormalizeBag(bag.most_common(40))  

        assemblyStruct = {}
        assemblyStruct['filename'] = filename
        assemblyStruct['tokenized'] = tokenizedAssembly
        assemblyStruct['bag_of_words'] = normalizedModel          

        return assemblyStruct

    # Tokenize from file full path
    def buildBag_FromFile(self, fileFullNamePath):
        
        bag = None
        
        jsonData = open(fileFullNamePath)
        tokenizedAssembly = json.load(jsonData)
        
        bag = self.buildBag_FromArray(tokenizedAssembly)
        
        return bag
                
class InstructionBagOfWordsModeler(AbstractBagOfWordsModeler):
    
    def __init__(self):
        pass
    
    # Builds bag of words for single assembly instructions
    def buildBag_FromArray(self, tokenizedAssembly):
        
        bag = Counter()
        
        for token in tokenizedAssembly:
            if 'type' in token:        
                if (token['type'] == 'INSTRUCTION' 
                    and token['name'] != 'dd' and token['name'] != 'call'
					and not any(c.isdigit() for c in token['name'])
					and not any(c=='_' for c in token['name'])
					and not any(c.isupper() for c in token['name'])
					):
                    bag[token['name']] += 1
    
        return bag
        
        
    def modelize(self, inputFilesFolder, outputFilesFolder):
        
        from os import listdir
        from os.path import isfile, join
        rawFilesList = [ f for f in listdir(inputFilesFolder) if isfile(join(inputFilesFolder,f)) ]
        
        tokenizedAssembliesList = []
        
        for filename in rawFilesList:
            fileFullNamePath = inputFilesFolder + "/" + filename

            
            if os.path.exists(fileFullNamePath):
                
                # Collect metainfo
                metaInfo = self.getMetainfo(fileFullNamePath, outputFilesFolder)
                
                # Build model action
                assemblyStruct = self.buildStruct_FromFile(inputFilesFolder, filename)
                tokenizedAssembliesList.append(assemblyStruct)
                
        docTermMatrix = self.build_DocTermMatrix(tokenizedAssembliesList);
        nDocTermMatrix = numpy.asarray(docTermMatrix)
        numpy.savetxt(outputFilesFolder + "/doc_term_matrix.csv", nDocTermMatrix, delimiter=",")        
     
     def getMetainfo(self, filename, outputFilesFolder):
         pass

class CallOperandsBagOfWordsModeler(AbstractBagOfWordsModeler):
    
    def __init__(self):
        pass
       
    # Build bag of words for "call"s operands, target DLL function
    def buildBag_FromArray(self, tokenizedAssembly):
        
        bag = Counter()
    
        for token in tokenizedAssembly:
            if 'type' in token:        
                if token['type'] == 'INSTRUCTION' and token['name'] == 'call':
                    operands = token['operands']                
                    for x in operands:
                        bag[x] +=1 
    
        return bag
