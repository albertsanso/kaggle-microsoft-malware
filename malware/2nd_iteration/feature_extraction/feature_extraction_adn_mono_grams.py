# -*- coding: utf-8 -*-
"""
Created on Thu Apr 02 11:31:43 2015

@author: Jordi
"""
import time
import pickle
import pandas as pd
import re
import os
import os.path
from collections import Counter
from IPython import parallel

#def clean_token_FromPath(folder):
def clean_token_FromFile(folder, filename):
    filePath = folder + "/" + filename + ".asm"
    cleanAssemblyLines = []
    if os.path.exists(filePath):
        inputLines = open(filePath).readlines()
        # First filtering task - Remove left side junk and full-line comments
        cleanAssemblyLines = clean_FromLinesArray(inputLines)
        cleanTokenAssemblyLines = tokenize_FromArray(cleanAssemblyLines) 
    #fileOutput = open(folder + "cleanToken/" + filename[0:len(filename)-4] + "cleanToken.pkl","wb")
    #pickle.dump(cleanTokenAssemblyLines, fileOutput)
    return cleanTokenAssemblyLines

def clean_FromLinesArray(linesArray):
    cleanAssemblyLines = []
    
    # Main regexp
    textSectionFirstFilterPattern = re.compile(
        "^(\.text|\.icode|CODE):([0-9a-zA-Z]{8,8})"
        "("
        "(\s[0-9a-zA-Z]{2,2}[\+]{0,1})+(\t+)(\s*)"
        "("
        "(?!\s*;)(.*)"
        ")"
        ")"
    )
    # Inline comments regexp
    innerCommentsFilterPattern = re.compile("(.*)(;.*)")
        
    for line in linesArray:
        match1 = textSectionFirstFilterPattern.search(line)
        if match1:
            filteredLine = match1.group(7)
            # Removes some more junk
            if not filteredLine.startswith("CC CC") and not filteredLine.startswith("00 00"):                    
            # Removes the Inline comments
                match2 = innerCommentsFilterPattern.search(filteredLine)
                if match2:
                    # Keep only the first match corresponding to the left side of the code line.
                    # The right side of the line is the comments substring
                    filteredLine2 = match2.group(1)
                    if not filteredLine2.startswith("db "):
                        cleanAssemblyLines.append(filteredLine2)
                else:
                    # The match is failed, so the line has no inline comments
                    if not filteredLine.startswith("db "):
                        cleanAssemblyLines.append(filteredLine)
                            
    return cleanAssemblyLines    

# Tokenize from text lines
def tokenize_FromArray(inputLinesArray):
    tokenizedAssembly = []
    for line in inputLinesArray:
        tokenizedLine = tokenizeAssemblyLine(line)
        if tokenizedLine != None:
            tokenizedAssembly.append(tokenizedLine)
    return tokenizedAssembly
   
# Tokenize 1 clean assembly code line    
def tokenizeAssemblyLine(assemblyLine):
    """
    Output structure:
        {
            'type': '',
            'name': '',
            'operands': ['', '', ... '']
        }
        """
    tokenStruct = None
    
    # Labels regexp
    labelPattern = re.compile(
        "^(\w+:)"
    )
    
    # Regular instrucion regexp
    instructionPattern = re.compile(
        "^(\w+)\s*(.*)"
    )

    # Search for Labels
    match1 = labelPattern.search(assemblyLine)
    if match1:
        labelName = match1.group(1)
        
        # Remove last ":" symbol label
        if labelName.endswith(":"): labelName = labelName[0:-1]

        tokenStruct = {}
        tokenStruct['type'] = 'LABEL'
        tokenStruct['name'] = labelName
    else:
        
        # Search for instructions
        match2 = instructionPattern.search(assemblyLine)
        if match2:
            instruction = match2.group(1)
            operands = match2.group(2)
            operands = [x.strip() for x in operands.split(',')] # THIS IS PYTHONICCCC !!!!!

            tokenStruct = {}
            tokenStruct['type'] = 'INSTRUCTION'
            tokenStruct['name'] = instruction
            tokenStruct['operands'] = operands
    
    return tokenStruct

########## read taula family instructions ADN
familyInstructions = pd.read_csv('C:/dev/source/python/work/bitbucket/malware/CSV/FamilyInstructions.csv', sep = ';')
#familyInstructions = pd.read_csv('C:/Users/Jordi/Documents/kaggle_malware/CSV/FamilyInstructions.csv', sep = ';')
#familyInstructions

########## create ADN codification
def createAdnFile(tokenFile):
    adnFileList = []
    for i in tokenFile:
        if i['type'] == "INSTRUCTION":
            word = i['name'].upper() 
            wordFamily = familyInstructions[familyInstructions.instruction == word]['familyInstructionCode'].values
            if wordFamily.size == 1:
                adnFileList.append(wordFamily[0])    
        else:
            print "no és una instrucció"
    adnFile = ''.join(adnFileList)
    return adnFile, adnFileList       

########## count ADN words of file
def countLettersAdnFile(adnFileList):
    lettersAdn = ['D','A','L','T','H','C','S','I','F','R','M']
    for letter in lettersAdn:
        tf = Counter()
        for word in adnFileList:
            tf[word] +=1
    return tf.items()

######## main 
"""trainAdnFeatures = pd.DataFrame(columns = ['D','A','L','T','H','C','S','I','F','R','M'])
trainAdnFeatures
folder = "D:/train/"
#f = "0A32eTdBKayjCWhZqDOQ"
i = 0
files = os.listdir(folder)
files  = [x for x in files if x.endswith(".asm")] #this is pythonic

for f in files:
    tokenFile = clean_token_FromFile(folder, f)
    adnFile, adnFileList = createAdnFile(tokenFile)
    fileOutput = open(folder + "adn/" + f[0:len(f)-4] + "adnFile.pkl","wb")
    pickle.dump(adnFile, fileOutput)   
    adnFileCountLetters = countLettersAdnFile(adnFileList)
    trainAdnFeatures.loc[i,'Id'] = f[0:len(f)-4]
    for j in adnFileCountLetters:
        trainAdnFeatures.loc[i,j[0]] = j[1]                
    print "el fitxer", f, "ja té ADN", time.strftime("%H:%M:%S")
    i = i+1

print trainAdnFeatures.head()   
trainAdnFeatures.shape
trainAdnFeatures.to_csv("C:/Users/Jordi/Documents/kaggle_malware/work/malware/datasets/definitive/train/trainAdnFeatures.csv")
"""
#### test
""" per fer
    el test sencer"""
"""
testAdnFeatures = pd.DataFrame(columns = ['D','A','L','T','H','C','S','I','F','R','M'])
testAdnFeatures
folder = "K:/datamandanga/test/"
#f = "0A32eTdBKayjCWhZqDOQ"
i = 0
files = os.listdir(folder)
files  = [x for x in files if x.endswith(".asm")] #this is pythonic

for f in files:
    tokenFile = clean_token_FromFile(folder, f)
    adnFile, adnFileList = createAdnFile(tokenFile)
    fileOutput = open(folder + "adn/" + f[0:len(f)-4] + "adnFile.pkl","wb")
    pickle.dump(adnFile, fileOutput)   
    adnFileCountLetters = countLettersAdnFile(adnFileList)
    testAdnFeatures.loc[i,'Id'] = f[0:len(f)-4]
    for j in adnFileCountLetters:
        testAdnFeatures.loc[i,j[0]] = j[1]                
    print "el fitxer", f, "ja té ADN", time.strftime("%H:%M:%S")
    i = i+1

print testAdnFeatures.head()   
testAdnFeatures.shape
testAdnFeatures.to_csv("C:/dev/source/python/work/bitbucket/malware/work/malware/datasets/definitive/test/FeaturesAdnTest.csv")
"""
""" codi per afegir 
    els fitxers que
    falten"""
folder = "K:/datamandanga/train/"
fileInput = open("C:/dev/source/python/work/bitbucket/malware/work/malware/filesTrainAdn.pkl","rb")
filesMissing = pickle.load(fileInput)
len(filesMissing)
filesMissing = list(filesMissing)
files = filesMissing[0:20]

file_prova = filesMissing[6]
print file_prova

def saveFilesMissingAdn(files, folder):
    i = 1.0
    for f in files:
        tokenFile = clean_token_FromFile(folder, f)
        adnFile, adnFileList = createAdnFile(tokenFile)
        fileOutput = open(folder + "adn/" + f[0:len(f)] + "adnFile.pkl","wb")
        pickle.dump(adnFile, fileOutput)  
        print "processat", i, "fitxers de", len(files),". % fet: ", i/len(files)*100
        i = i+1
    return
    
#t0 = time.time() 
saveFilesMissingAdn(filesMissing, folder)
#print "Time in seconds (Computations): ", time.time() - t0     



clients = parallel.Client()
#clients.block = True
print clients.ids

#dview = clients.direct_view()
lview_all = clients.load_balanced_view()  
t0 = time.time() 
async = lview_all.map(saveFilesMissingAdn(files, folder), block = False)
"""
i = 1;
print "hola"
for result in async:        
    print "Task", i ," executed by engine ", result
    i = i + 1
"""
print "Time in seconds (Computations): ", time.time() - t0     
