# -*- coding: utf-8 -*-

import csv
import random
import os
import os.path
import re

import pandas as pd
import numpy as np


from collections import Counter

def getImportedSysCalls(folder, filename):
    
    filePath = folder + "/" + filename + ".asm"
    
    sysCallFilterIDataSection = re.compile(
        "^(\.idata):([0-9a-zA-Z]{8,8})"
        "\s(.*)extrn\s(.*):dword"
    )
    
    importedSysCalls = []
    
    if os.path.exists(filePath):
        inputLines = open(filePath).readlines()

        for line in inputLines:
            match1 = sysCallFilterIDataSection.search(line)
            if (match1):
                syscall = match1.group(4)
                importedSysCalls.append(syscall)
                
    return importedSysCalls

def extractSysCalls(folder, filename, importedSyscallsList, threshold):
    
    sysCallCounter = Counter()
    
    filePath = folder + "/" + filename + ".asm"
    
    instructionFilter = re.compile(
        "^(\.text|\.icode):([0-9a-zA-Z]{8,8})"
        "("
          "(\s[0-9a-zA-Z]{2,2}[\+]{0,1})+(\t+)(\s*)"
          "("
            "(?!\s*;)(.*)"
          ")"
        ")"
    )
    
    callsFilter = re.compile(
        "^\s*call(\t|\s)*(ds:)*(.*)"
    )

    if os.path.exists(filePath):
        inputLines = open(filePath).readlines()

        for line in inputLines:
            match1 = instructionFilter.search(line)
            if (match1):
                instructionLine = match1.group(7)
                match2 = callsFilter.search(instructionLine)
                if (match2):
                    callOperand = match2.group(3)
                    
                    if (not callOperand.startswith('_')):
                        if any(callOperand in s for s in importedSyscallsList):                        
                            #print callOperand + " - " + instructionLine
                            sysCallCounter[callOperand] += 1
    
    sysCallCounter = Counter(el for el in sysCallCounter.elements() if sysCallCounter[el] > threshold)

    return sysCallCounter

def simpleNormalizeBag(bag):
    normalizedBag = []
    
    if len(bag) > 0:
        labels, values = zip(*bag)
        totalSum = float(sum(values))
        
        for tpl in bag:
            occurrences = tpl[1]
            normalizedOccurrences = occurrences/totalSum
            normalizedTuple = (tpl[0], normalizedOccurrences)
            normalizedBag.append(normalizedTuple)
        
    return normalizedBag
        
def getSysCallsCount_FromFile(folder, filename, threshold):
    importedSyscallsList = getImportedSysCalls(folder, filename)
    sysCallsStats = extractSysCalls(folder, filename, importedSyscallsList, threshold)
    return sysCallsStats

def getSamples(seed, bucketSize):
    samplesStruct = {'my_hash':{}, 'my_list':[]}
    
    fileFullPath = "resource/testLabels.csv"
    
    random.seed(seed)
    
    csvfile = open(fileFullPath, 'rb')
    samples = csv.reader(csvfile, delimiter=',')
    
    for row in samples:
        
        sampleName = row[0]
        sampleCategory = row[1]
        samplesStruct['my_hash'][sampleName] = sampleCategory
        samplesStruct['my_list'].append(sampleName)
        
    if (bucketSize > len(samplesStruct['my_list'])):
        bucketSize = len(samplesStruct['my_list'])
    samplesStruct['my_list'] = random.sample(samplesStruct['my_list'], bucketSize)
    
    return samplesStruct
 
def buildLexicon(corpus):
    lexicon = set()
    for doc in corpus:
        if 'counter' in doc:
            bagOfWords = doc['counter']
            if bagOfWords != None:
                wordsList = list(bagOfWords)
                #print wordsList
                for word in wordsList:
                    lexicon.update([word])
            
    return lexicon 
    
def termFreq(term, doc):
    if (doc != None):
        for myTuple in doc:
            if myTuple[0] == term:
                return myTuple[1]
    return 0
        
# -----------------------------------------------------------------------------

def go(theSeed, samplesNumber, threshold):
    samples = getSamples(theSeed, samplesNumber)
    samplesNumber = len(samples['my_list'])
    doneSamples = 0
    
    folder = "D:/data/mandanga/malware_classification/test"
    statsList = []
    for sampleId in samples['my_list']:
        fileSysCallsStats = getSysCallsCount_FromFile(folder, sampleId, threshold)
        sysCallStruct = {}
        #sysCallStruct['counter'] = fileSysCallsStats.most_common()
        sysCallStruct['counter'] = fileSysCallsStats
        sysCallStruct['id'] = sampleId
        statsList.append(sysCallStruct)
        
        pcDone = (float(doneSamples)/samplesNumber)*100
        doneSamples+=1
        print "Extracting Syscalls. Percent finished: " + str(pcDone)

    
    matrix = []
    vocabulary = buildLexicon(statsList)
    statsLen = len(statsList)
    statsDone = 0
    for struct in statsList:
        doc = struct['counter'].most_common()
        sampleId = struct['id']
       
        tf_vector = [termFreq(word, doc) for word in vocabulary]
        tf_vector.insert(0, sampleId)
        tf_vector.append(samples['my_hash'][sampleId])    
        matrix.append(tf_vector)
        
        pcDone = (float(statsDone)/statsLen)*100
        statsDone += 1
        print "Calculating Term Matrix. Percent finished: " + str(pcDone)
        
    vocabulary = list(vocabulary)
    vocabulary.insert(0, 'id')
    vocabulary.append('category')
    
    docTermMatrix = (vocabulary, matrix)
    vocabulary, nDocTermMatrix = np.asarray(docTermMatrix)
    df = pd.DataFrame(data=nDocTermMatrix, columns=vocabulary)
    
    df.to_csv("datasets/definitive/test/win32_api_calls_count_thresh_"+str(threshold)+".csv", index=False)

# -----------------------------------------------------------------------------
    
theSeed = "my_seed"
samplesNumber = 100
threshold = 5
#go(theSeed, samplesNumber, threshold)

go("my_seed", 11000, 2)
go("my_seed", 11000, 5)
go("my_seed", 11000, 20)
go("my_seed", 11000, 10)







