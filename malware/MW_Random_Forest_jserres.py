# -*- coding: utf-8 -*-

from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

"""
#pd.set_option('display.expand_max_repr', False)
pd.set_option('display.max_columns', 50)
pd.set_option('display.width', None)
pd.set_option('display.line_width', 200)
"""

#df=pd.read_csv('C:/Users/Jordi/Documents/kaggle_malware/work/malware/datasets/code_segments_size_10000samples_70percent.csv', sep=',')
df=pd.read_csv('C:/Users/Jordi/Documents/kaggle_malware/work/malware/datasets/definitive/train/segments_relative_size_10868samples.csv', sep=',')
sizeFiles = pd.read_csv('C:/Users/Jordi/Documents/kaggle_malware/work/malware/datasets/definitive/train/sizeFilesTrain.csv', sep=',')

###### add column with size file
df.head()
dfTotal = pd.merge(df, sizeFiles, how = 'left', left_on = 'sample_id', right_on = 'Id')
dfTotal.head()
dfTotal.drop(['Id', 'Id_ext'], axis = 1, inplace = True)
dfTotal.drop(['Unnamed: 0_y'], axis = 1, inplace = True)
dfTotal.head()
dfTotal.shape


colNames = dfTotal.columns.tolist()
print colNames
type(colNames)
print colNames[-3:]

colNames[:-2]
type(colNames[:-2])
colNames[-1]
type(colNames[-1])
colNames[-2]
colNamesSort = colNames[:-2] + [colNames[-1]] + [colNames[-2]]
print colNamesSort

dfTotal = dfTotal[colNamesSort]
dfTotal.head()
dfTotal.



"""
df.head()
df.shape
data = pd.merge(df,fileSize, how = 'left', left_on = 'sample_id', right_on = 'Id')
data.shape
data.drop('Id',1)
data = data.drop('Id',1)
print data
data = data.drop('Id_ext',1)


cols = list(data.columns.values)
print cols

data_values = data.values
print data_values
data_values.shape


data_segments = data_values[:,:-2]
print data_segments
data_segments.shape
data_labels = data_values[:,322]
print data_labels
data_size = data_values[:,-1]
print data_size
data_size.shape
data_segments_size = np.concatenate((data_segments, data_size.T), axis = 1)
print data_size.T
data_size_transp = data_size.T
data_size_transp.shape
data_size.T?

a =

###
ds = data.values
X = ds[:,2:-2] + ds[:,-1]
"""
ds =dfTotal.values
#ds = df.values
ds.shape
X = ds[:,2:-1] # all samples
y = ds[:,-1] # Labels
X
y


perm = np.random.permutation(y.size)
#print perm
PRC = 0.7
split_point = int(np.ceil(y.shape[0]*PRC))

X_train = X[perm[:split_point].ravel(),:]
y_train = y[perm[:split_point].ravel()]
print type(y_train[2])
y_train = y_train[:].astype(int)
print y_train
print type(y_train[2])
print X_train
print X_train.shape
print y_train.shape



X_test = X[perm[split_point:].ravel(),:]
y_test = y[perm[split_point:].ravel()]
y_test = y_test[:].astype(int)
print y_test.shape

random_state = 123
n_jobs = -1
#max_depth = 

verbose = 2

clf = RandomForestClassifier(random_state=random_state)
#clf = RandomForestClassifier(random_state=random_state, n_jobs=n_jobs, verbose = verbose)
#clf = RandomForestClassifier(random_state=random_state,max_depth = max_depth, n_jobs=n_jobs, verbose = verbose)
# Start training
#print('training started')
clf.fit(X_train, y_train)
print('training completed')

#Check on the training set and visualize performance
yhat = clf.predict(X_train)
yhat = yhat[:].astype(int)
print yhat

print "\nTRAINING STATS:"
print "classification accuracy:", metrics.accuracy_score(yhat, y_train)

plt.imshow(metrics.confusion_matrix(y_train, yhat), cmap=plt.cm.binary, interpolation='nearest')
#plt.imshow?

plt.xlabel('Training confusion matrix')
plt.colorbar()

#Check on the test set and visualize performance
yhat=clf.predict(X_test)
yhat_total = clf.predict_proba(X_test)
print yhat_total[0:25,:]
print yhat_total
print metrics.classification_report(y_test, yhat)
metrics.classification_report?
yhat.shape
yhat = yhat[:].astype(int)

print "TESTING STATS:"
print "classification accuracy:", metrics.accuracy_score(yhat, y_test)
plt.figure()
plt.imshow(metrics.confusion_matrix(y_test, yhat), cmap=plt.cm.binary, interpolation='nearest')
plt.xlabel('Testing confusion matrix')
plt.colorbar()

plt.figure()
conf_matrix = plt.imshow(metrics.confusion_matrix(y_test, yhat), cmap=plt.cm.spectral, aspect = 'equal',interpolation='nearest')
plt.xlabel('Testing confusion matrix')
plt.colorbar()



plt.figure()
plt.imshow(metrics.confusion_matrix(y_test, yhat), cmap=plt.cm.spectral, aspect = 'equal',interpolation='nearest')
plt.xlabel('Testing confusion matrix')
plt.colorbar()


plt.figure()
plt.imshow(metrics.confusion_matrix(y_test, yhat), interpolation='nearest')
plt.xlabel('Testing confusion matrix')
plt.colorbar()

mat_conf = metrics.confusion_matrix(y_test, yhat)
print mat_conf
a = mat_conf.sum(axis = 1)
print a
print mat_conf
mat_conf = mat_conf[:].asype(int)
mat_norm = mat_conf / a
print mat_norm

print mat_conf / (2,2,2,2,2,2,2,2,2)

mat_norm
mat_conf


plt.figure()
plt.imshow(metrics.confusion_matrix(y_test, yhat), interpolation='nearest')
plt.xlabel('Testing confusion matrix')
plt.colorbar()


matplotlib.colors.Colormap?
plt.cm.binary?









type(yhat)
yhat_total_corregit = yhat_total + 0.01

print metrics.classification_report(y_test,yhat)
print metrics.accuracy_score(y_test, yhat)
metrics.log_loss(y_test, yhat_total, 1e-15)
metrics.log_loss(y_test, yhat_total + 0.001, 1e-15)
print yhat_total+0.01
import numpy as np

#np.clip?

def multiclass_log_loss(y_true, y_pred, eps=1e-15):
    predictions = np.clip(y_pred, eps, 1 - eps)  # força que l'interval sigui com a màxim [eps, 1-eps]
    print predictions
    #normalize row sums to 1
    #predictions /= predictions.sum(axis=1)[:, np.newaxis]
    
    actual = np.zeros(y_pred.shape)
    n_samples = actual.shape[0]
    
    actual[np.arange(n_samples), y_true.astype(int)] = 1
    vectsum = np.sum(actual * np.log(predictions))
    loss = -(1.0 / n_samples) * vectsum
    return loss

kaggle_result = multiclass_log_loss(y_test, yhat_total)